{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# INF8225 - PIAD - Anomaly Detection\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_uquztLgYiox"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Import & Git"
   ],
   "metadata": {
    "id": "cUlI8PexXGvW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import git projet\n",
    "\n",
    "!git clone https://github.com/deca1111/Anomaly_Detection_Comparison.git\n",
    "\n",
    "# changement de folder\n",
    "%cd /content/Anomaly_Detection_Comparison/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B89BUb_3brxp",
    "outputId": "8c6ce2d6-b8c5-4b2e-9432-8e920fc75e2f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'INF8225-Projet'...\n",
      "remote: Enumerating objects: 2104, done.\u001B[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001B[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001B[K\n",
      "remote: Total 2104 (delta 18), reused 61 (delta 16), pack-reused 2041\u001B[K\n",
      "Receiving objects: 100% (2104/2104), 469.55 MiB | 41.59 MiB/s, done.\n",
      "Resolving deltas: 100% (676/676), done.\n",
      "/content/INF8225-Projet\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Instalation modules utiles\n",
    "# ! pip install -r requirements.txt\n",
    "\n",
    "! pip install tensorboardX\n",
    "! pip install pyyaml\n",
    "! pip install patool"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SbAzceWbjpG",
    "outputId": "ac5acae1-261a-4407-9d8a-798f9c117b19"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/101.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.7/101.7 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
      "Collecting patool\n",
      "  Downloading patool-2.2.0-py2.py3-none-any.whl (96 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.0/96.0 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: patool\n",
      "Successfully installed patool-2.2.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPnq0VgmYgFT",
    "outputId": "3e2a635d-5ca4-4f06-e5da-186a622220f3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import utiles\n",
    "\n",
    "from anomaly_detection.piad.train import Trainer\n",
    "from anomaly_detection.piad.evaluate import evaluate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import urllib.request\n",
    "import patoolib\n",
    "\n",
    "import subprocess\n",
    "from multiprocessing import Process\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dataset"
   ],
   "metadata": {
    "id": "8Duc6vPDq2mS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unzip Dataset"
   ],
   "metadata": {
    "id": "pvezkyanXECg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "compressedFile = \"/content/Anomaly_Detection_Comparison/data/data/nih/subset_300_zip/images_subset_300.zip\"\n",
    "\n",
    "targetImagesRoot = \"/content/Anomaly_Detection_Comparison/data/data/nih_300/\"\n",
    "\n",
    "# Création folder\n",
    "os.makedirs(targetImagesRoot, exist_ok=True)\n",
    "\n",
    "# Unzip\n",
    "patoolib.extract_archive(compressedFile, outdir=targetImagesRoot)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "BBkPetcxXT6Y",
    "outputId": "587d19d2-9a14-45a1-86e7-51e000364ff7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO patool: Extracting /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip ...\n",
      "INFO:patool:Extracting /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip ...\n",
      "INFO patool: running /usr/bin/7z x -o/content/INF8225-Projet/data/data/nih_300/ -- /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip\n",
      "INFO:patool:running /usr/bin/7z x -o/content/INF8225-Projet/data/data/nih_300/ -- /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip\n",
      "INFO patool:     with input=''\n",
      "INFO:patool:    with input=''\n",
      "INFO patool: ... /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip extracted to `/content/INF8225-Projet/data/data/nih_300/'.\n",
      "INFO:patool:... /content/INF8225-Projet/data/data/nih/subset_300_zip/images_subset_300.zip extracted to `/content/INF8225-Projet/data/data/nih_300/'.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/content/INF8225-Projet/data/data/nih_300/'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vérification du Subset"
   ],
   "metadata": {
    "id": "xSuO5tKPeyVb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "listImagesFile = \"/content/Anomaly_Detection_Comparison/data/data/nih/images_subset_300.txt\"\n",
    "\n",
    "rootImages = \"/content/Anomaly_Detection_Comparison/data/data/nih_300/\"\n",
    "\n",
    "# vérification que l'intégralité des images du subset est présent\n",
    "\n",
    "with open(listImagesFile, 'r') as f:\n",
    "    listImages = f.read().splitlines()\n",
    "\n",
    "imagesManquantes = []\n",
    "nbImages = 0\n",
    "for image in listImages:\n",
    "    if not os.path.exists(rootImages + image):\n",
    "        imagesManquantes.append(image)\n",
    "    else :\n",
    "        nbImages += 1\n",
    "\n",
    "if len(imagesManquantes) > 0:\n",
    "  print(f\"Images manquantes : {imagesManquantes}\")\n",
    "else:\n",
    "  print(f\"Tous les images du subset sont présentes [{nbImages}/{len(listImages)}]\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n6QG3cbcqXZ",
    "outputId": "68cdfd01-e9ca-4640-ea77-e91f162126b3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tous les images du subset sont présentes [7311/7311]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrainement et évaluation"
   ],
   "metadata": {
    "id": "wEG-QZAMk1ux"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Config piad\n",
    "model = \"piad\"\n",
    "dataset = \"nih\"\n",
    "exp = \"with_cv\"\n",
    "_class = \"subset\"\n",
    "\n",
    "\n",
    "RUNS = ['0', '1', '2']\n",
    "\n",
    "configs = []\n",
    "\n",
    "for run in RUNS:\n",
    "\n",
    "  config = f\"configs/{model}/{dataset}/final/{exp}/class_{_class}/run_{run}/train_eval.yaml\"\n",
    "\n",
    "  print(config)\n",
    "  configs.append(config)\n",
    "\n",
    "def _load_config(path):\n",
    "    with open(path, 'r') as stream:\n",
    "        config = yaml.load(stream, Loader=yaml.FullLoader)\n",
    "    return config"
   ],
   "metadata": {
    "id": "kPWEPOKhnzWS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "10b6e1f7-cd53-441b-c7d4-9d4af7d1a91b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "configs/piad/nih/final/with_cv/class_subset/run_0/train_eval.yaml\n",
      "configs/piad/nih/final/with_cv/class_subset/run_1/train_eval.yaml\n",
      "configs/piad/nih/final/with_cv/class_subset/run_2/train_eval.yaml\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run 0"
   ],
   "metadata": {
    "id": "MS88BN7FrXJv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "id": "ZGGwSC-HrkZG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "trainer = Trainer(_load_config(configs[0]))\n",
    "trainer.train()\n",
    "print(f\"Training is complete. Took: {(time.time() - start_time) / 60:.02f}m\")\n",
    "del trainer"
   ],
   "metadata": {
    "id": "lmlbJfpIkwPR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e442b19b-a750-40a4-e35c-beacf887490e"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_kwargs:\n",
      "  ddis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  edis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  enc_dec:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0002\n",
      "batch_size: 32\n",
      "checkpoint_root: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "ddis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 128\n",
      "    - 128\n",
      "  type: residual9\n",
      "dec:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 256\n",
      "    - 256\n",
      "    - 128\n",
      "    - 64\n",
      "    - 32\n",
      "  type: residual9\n",
      "edis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 1024\n",
      "    - 1024\n",
      "enc:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 256\n",
      "  type: residual9\n",
      "finetune_from: null\n",
      "image_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "image_dim: 1\n",
      "image_rec_loss:\n",
      "  loss_kwargs:\n",
      "    feature_weights:\n",
      "      r42: 1\n",
      "    img_weight: 0\n",
      "  loss_type: relative_perceptual_L1\n",
      "image_res: 64\n",
      "image_sample_iter: 5000\n",
      "initial_image_res: 64\n",
      "iters: 40000\n",
      "latent_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "latent_dim: 256\n",
      "latent_res: 1\n",
      "log_iter: 10\n",
      "log_root: ./data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "n_dis: 2\n",
      "random_seed: 8439\n",
      "results_root: ./data/results/piad/nih/final/with_cv/class_subset/run_0\n",
      "test_batch_size: 32\n",
      "test_datasets:\n",
      "  anomaly:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/anomaly/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "  normal:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "test_model_path: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/anomaly_detection.tar\n",
      "train_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "update_grad_norm_iter: 100\n",
      "val_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "val_iter: 1000000\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================== MODELS ON LARGEST RESOLUTION ==================================\n",
      "====================== Encoder =============================\n",
      "STABNetwork(\n",
      "  (model): Sequential(\n",
      "    (preprocess_res_64): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): PreActResnetBlock(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (res_64): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_32): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_16): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_8): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_4): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2)\n",
      "      (1): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "====================== Decoder  ===========================\n",
      "STABNetwork(\n",
      "  (model): Sequential(\n",
      "    (res_4): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2)\n",
      "      (1): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), padding=(3, 3))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_8): Sequential(\n",
      "      (0): PreActResnetBlockUp(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_16): Sequential(\n",
      "      (0): PreActResnetBlockUp(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_32): Sequential(\n",
      "      (0): PreActResnetBlockUp(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_64): Sequential(\n",
      "      (0): PreActResnetBlockUp(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode='nearest')\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (postprocess_res_64): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2)\n",
      "      (1): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "====================== Discriminator of decoder ==========\n",
      "STABNetwork(\n",
      "  (model): Sequential(\n",
      "    (preprocess_res_64): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): PreActResnetBlock(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (res_64): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_32): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (1): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_16): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_8): Sequential(\n",
      "      (0): PreActResnetBlockDown(\n",
      "        (model): Sequential(\n",
      "          (0): LeakyReLU(negative_slope=0.2)\n",
      "          (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "          (2): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.2)\n",
      "            )\n",
      "          )\n",
      "          (3): ConvBlock(\n",
      "            (model): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (skipcon): Sequential(\n",
      "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res_4): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2)\n",
      "      (1): ConvBlock(\n",
      "        (model): Sequential(\n",
      "          (0): Conv2d(128, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "====================== Discriminator of encoder ============\n",
      "LatentDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "===================================================================================================\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "\n",
      "  0%|          | 0.00/548M [00:00<?, ?B/s]\u001B[A\n",
      "  2%|▏         | 10.0M/548M [00:00<00:05, 105MB/s]\u001B[A\n",
      "  5%|▍         | 27.1M/548M [00:00<00:03, 148MB/s]\u001B[A\n",
      "  8%|▊         | 44.9M/548M [00:00<00:03, 166MB/s]\u001B[A\n",
      " 11%|█▏        | 63.0M/548M [00:00<00:02, 175MB/s]\u001B[A\n",
      " 15%|█▍        | 81.0M/548M [00:00<00:02, 180MB/s]\u001B[A\n",
      " 18%|█▊        | 99.2M/548M [00:00<00:02, 184MB/s]\u001B[A\n",
      " 21%|██▏       | 117M/548M [00:00<00:02, 185MB/s] \u001B[A\n",
      " 25%|██▍       | 135M/548M [00:00<00:02, 187MB/s]\u001B[A\n",
      " 28%|██▊       | 153M/548M [00:00<00:02, 188MB/s]\u001B[A\n",
      " 31%|███▏      | 172M/548M [00:01<00:02, 188MB/s]\u001B[A\n",
      " 35%|███▍      | 190M/548M [00:01<00:01, 189MB/s]\u001B[A\n",
      " 38%|███▊      | 208M/548M [00:01<00:01, 189MB/s]\u001B[A\n",
      " 41%|████      | 226M/548M [00:01<00:01, 187MB/s]\u001B[A\n",
      " 45%|████▍     | 244M/548M [00:01<00:01, 188MB/s]\u001B[A\n",
      " 48%|████▊     | 262M/548M [00:01<00:01, 189MB/s]\u001B[A\n",
      " 51%|█████     | 280M/548M [00:01<00:01, 190MB/s]\u001B[A\n",
      " 55%|█████▍    | 299M/548M [00:01<00:01, 190MB/s]\u001B[A\n",
      " 58%|█████▊    | 317M/548M [00:01<00:01, 190MB/s]\u001B[A\n",
      " 61%|██████    | 335M/548M [00:01<00:01, 190MB/s]\u001B[A\n",
      " 64%|██████▍   | 353M/548M [00:02<00:01, 190MB/s]\u001B[A\n",
      " 68%|██████▊   | 371M/548M [00:02<00:00, 189MB/s]\u001B[A\n",
      " 71%|███████   | 390M/548M [00:02<00:00, 190MB/s]\u001B[A\n",
      " 74%|███████▍  | 408M/548M [00:02<00:00, 190MB/s]\u001B[A\n",
      " 78%|███████▊  | 426M/548M [00:02<00:00, 190MB/s]\u001B[A\n",
      " 81%|████████  | 444M/548M [00:02<00:00, 191MB/s]\u001B[A\n",
      " 84%|████████▍ | 463M/548M [00:02<00:00, 191MB/s]\u001B[A\n",
      " 88%|████████▊ | 481M/548M [00:02<00:00, 189MB/s]\u001B[A\n",
      " 91%|█████████ | 499M/548M [00:02<00:00, 190MB/s]\u001B[A\n",
      " 94%|█████████▍| 517M/548M [00:02<00:00, 190MB/s]\u001B[A\n",
      "100%|██████████| 548M/548M [00:03<00:00, 186MB/s]\n",
      "  0%|          | 1/40000 [00:05<63:52:44,  5.75s/it]"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40000/40000 [2:05:40<00:00,  5.46it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model training is complete.\n",
      "Training is complete. Took: 125.75m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sauvegarde des poids du modèle dans un zip & Copie dans le drive"
   ],
   "metadata": {
    "id": "0kIXXoyRQrQL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "targetFolder = f\"/content/Anomaly_Detection_Comparison/data/checkpoint_tmp/{model}/{dataset}/final/{exp}/class_{_class}/run_{RUNS[0]}\"\n",
    "os.makedirs(targetFolder, exist_ok=True)\n",
    "\n",
    "modelName = f\"{model}__{dataset}__{exp}__class_{_class}__run_{RUNS[0]}\"\n",
    "outputFile = f\"/content/Anomaly_Detection_Comparison/data/model_{modelName}.zip\"\n",
    "\n",
    "# Sauvegarde dans un fichier zip\n",
    "\n",
    "!zip -r $outputFile $targetFolder"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lloVJgH4Q1dR",
    "outputId": "73f8a1a0-a93e-4d64-925b-66aaa6e02789"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "updating: content/INF8225-Projet/data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/checkpoint.tar (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/anomaly_detection_niter_40000.tar (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/anomaly_detection.tar (deflated 7%)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ajout du drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxaXWar7fQ-I",
    "outputId": "b877f7d9-9565-41a5-a3a9-936949d0ea1e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "inputFile = outputFile\n",
    "outputFiles = f\"/content/drive/MyDrive/Polytechnique/INF8225/Projet/modelSave/{modelName}.zip\"\n",
    "\n",
    "!cp $inputFile $outputFiles"
   ],
   "metadata": {
    "id": "goSDuvEHfaEo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sauvegarde des logs de l'entrainement dans un zip & Copie dans le drive"
   ],
   "metadata": {
    "id": "iXBmZAiogImm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sauvegarde des logs dans un zip puis dans le drive\n",
    "\n",
    "targetLogsFolder = f\"/content/Anomaly_Detection_Comparison/data/logs_tmp/{model}/{dataset}/final/{exp}/class_{_class}/run_{RUNS[0]}\"\n",
    "os.makedirs(targetLogsFolder, exist_ok=True)\n",
    "\n",
    "logsFile = f\"/content/Anomaly_Detection_Comparison/data/logs_{modelName}.zip\"\n",
    "\n",
    "!zip -r $logsFile $targetLogsFolder\n",
    "\n",
    "driveOutputRoot = \"/content/drive/MyDrive/Polytechnique/INF8225/Projet/logs/\"\n",
    "os.makedirs(driveOutputRoot, exist_ok=True)\n",
    "\n",
    "outputFiles = os.path.join(driveOutputRoot, f\"logs_{modelName}.zip\")\n",
    "\n",
    "!cp $logsFile $outputFiles\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PLYAjlogIY9",
    "outputId": "011da0f3-d161-4010-ad3c-7dde61ec0bc0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/events.out.tfevents.1713037499.fdb8694e1136 (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/norm/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/norm/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/gp/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/gp/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/wass/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/ddis/wass/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/rec_loss_weight_enc/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/rec_loss_weight_enc/events.out.tfevents.1713037821.fdb8694e1136 (deflated 74%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/image_rec_loss/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/image_rec_loss/events.out.tfevents.1713037821.fdb8694e1136 (deflated 68%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/rec_loss_weight_dec/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/rec_loss_weight_dec/events.out.tfevents.1713037821.fdb8694e1136 (deflated 74%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/latent_adv_loss/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/latent_adv_loss/events.out.tfevents.1713037821.fdb8694e1136 (deflated 68%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/image_adv_loss/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/enc_dec/image_adv_loss/events.out.tfevents.1713037821.fdb8694e1136 (deflated 68%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/norm/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/norm/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/gp/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/gp/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/wass/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/train/edis/wass/events.out.tfevents.1713037821.fdb8694e1136 (deflated 66%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/events.out.tfevents.1713037810.fdb8694e1136 (deflated 8%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/tensorboard/events.out.tfevents.1713037422.fdb8694e1136 (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/ (stored 0%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_35000.png (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_15000.png (deflated 6%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_40000.png (deflated 6%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_10000.png (deflated 6%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_30000.png (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_25000.png (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/sample.png (deflated 6%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_20000.png (deflated 7%)\n",
      "updating: content/INF8225-Projet/data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0/images/res_64_niter_5000.png (deflated 7%)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "qwbINBvkhSVD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Évaluation"
   ],
   "metadata": {
    "id": "vs-PLUHTqsKM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "evaluate(_load_config(configs[0]))\n",
    "\n",
    "print(f\"Evaluation is complete. Took: {(time.time() - start_time) / 60:.02f}m\")"
   ],
   "metadata": {
    "id": "QPhJ3LQ4kzQZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d2d76f1-d174-48bf-aaa6-ca7fce07f3dc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adam_kwargs:\n",
      "  ddis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  edis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  enc_dec:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0002\n",
      "batch_size: 32\n",
      "checkpoint_root: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "ddis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 128\n",
      "    - 128\n",
      "  type: residual9\n",
      "dec:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 256\n",
      "    - 256\n",
      "    - 128\n",
      "    - 64\n",
      "    - 32\n",
      "  type: residual9\n",
      "edis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 1024\n",
      "    - 1024\n",
      "enc:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 256\n",
      "  type: residual9\n",
      "finetune_from: null\n",
      "image_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "image_dim: 1\n",
      "image_rec_loss:\n",
      "  loss_kwargs:\n",
      "    feature_weights:\n",
      "      r42: 1\n",
      "    img_weight: 0\n",
      "  loss_type: relative_perceptual_L1\n",
      "image_res: 64\n",
      "image_sample_iter: 5000\n",
      "initial_image_res: 64\n",
      "iters: 40000\n",
      "latent_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "latent_dim: 256\n",
      "latent_res: 1\n",
      "log_iter: 10\n",
      "log_root: ./data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "n_dis: 2\n",
      "random_seed: 8439\n",
      "results_root: ./data/results/piad/nih/final/with_cv/class_subset/run_0\n",
      "test_batch_size: 32\n",
      "test_datasets:\n",
      "  anomaly:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/anomaly/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "  normal:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "test_model_path: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/anomaly_detection.tar\n",
      "train_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "update_grad_norm_iter: 100\n",
      "val_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "val_iter: 1000000\n",
      "verbose: true\n",
      "\n",
      "Starting model evaluation ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 27.49it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 26.48it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model evaluation is complete. Results: \n",
      "   niter   ROC AUC\n",
      "0  40000  0.884784\n",
      "Evaluation is complete. Took: 0.06m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All runs together (subprocess)"
   ],
   "metadata": {
    "id": "ebhs6_6D7n1j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "⚠ Je n'ai pas réussi à faire fonctionner cette partie dans colab, on ne fait donc qu'une run à la fois"
   ],
   "metadata": {
    "id": "VPUNVI1veGs0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# def run_training(config):\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     trainer = Trainer(_load_config(config))\n",
    "#     trainer.train()\n",
    "#     print(f\"Training is complete. Took: {(time.time() - start_time) / 60:.02f}m\")\n",
    "#     del trainer\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     evaluate(_load_config(config))\n",
    "#     print(f\"Evaluation is complete. Took: {(time.time() - start_time) / 60:.02f}m\")"
   ],
   "metadata": {
    "id": "NBevtITz-WZ6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Lancement des 3 runs en mêmes temps\n",
    "# for config in configs:\n",
    "#     p = Process(target=run_training, args=(config,))\n",
    "#     p.start()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUaO6uyT7yYm",
    "outputId": "f92cf56a-1df3-4945-92f6-6a70f4f0541a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adam_kwargs:\n",
      "  ddis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  edis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  enc_dec:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0002\n",
      "batch_size: 32\n",
      "checkpoint_root: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "ddis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 128\n",
      "    - 128\n",
      "  type: residual9\n",
      "dec:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 256\n",
      "    - 256\n",
      "    - 128\n",
      "    - 64\n",
      "    - 32\n",
      "  type: residual9\n",
      "edis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 1024\n",
      "    - 1024\n",
      "enc:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 256\n",
      "  type: residual9\n",
      "finetune_from: null\n",
      "image_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "image_dim: 1\n",
      "image_rec_loss:\n",
      "  loss_kwargs:\n",
      "    feature_weights:\n",
      "      r42: 1\n",
      "    img_weight: 0\n",
      "  loss_type: relative_perceptual_L1\n",
      "image_res: 64\n",
      "image_sample_iter: 5000\n",
      "initial_image_res: 64\n",
      "iters: 40000\n",
      "latent_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "latent_dim: 256\n",
      "latent_res: 1\n",
      "log_iter: 10\n",
      "log_root: ./data/logs_tmp/piad/nih/final/with_cv/class_subset/run_0\n",
      "n_dis: 2\n",
      "random_seed: 8439\n",
      "results_root: ./data/results/piad/nih/final/with_cv/class_subset/run_0\n",
      "test_batch_size: 32\n",
      "test_datasets:\n",
      "  anomaly:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/anomaly/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "  normal:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "test_model_path: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_0/anomaly_detection.tar\n",
      "train_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "update_grad_norm_iter: 100\n",
      "val_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "val_iter: 1000000\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adam_kwargs:\n",
      "  ddis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  edis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  enc_dec:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0002\n",
      "batch_size: 32\n",
      "checkpoint_root: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_1\n",
      "ddis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 128\n",
      "    - 128\n",
      "  type: residual9\n",
      "dec:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 256\n",
      "    - 256\n",
      "    - 128\n",
      "    - 64\n",
      "    - 32\n",
      "  type: residual9\n",
      "edis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 1024\n",
      "    - 1024\n",
      "enc:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 256\n",
      "  type: residual9\n",
      "finetune_from: null\n",
      "image_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "image_dim: 1\n",
      "image_rec_loss:\n",
      "  loss_kwargs:\n",
      "    feature_weights:\n",
      "      r42: 1\n",
      "    img_weight: 0\n",
      "  loss_type: relative_perceptual_L1\n",
      "image_res: 64\n",
      "image_sample_iter: 5000\n",
      "initial_image_res: 64\n",
      "iters: 40000\n",
      "latent_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "latent_dim: 256\n",
      "latent_res: 1\n",
      "log_iter: 10\n",
      "log_root: ./data/logs_tmp/piad/nih/final/with_cv/class_subset/run_1\n",
      "n_dis: 2\n",
      "random_seed: 5375\n",
      "results_root: ./data/results/piad/nih/final/with_cv/class_subset/run_1\n",
      "test_batch_size: 32\n",
      "test_datasets:\n",
      "  anomaly:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/anomaly/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "  normal:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "test_model_path: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_1/anomaly_detection.tar\n",
      "train_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "update_grad_norm_iter: 100\n",
      "val_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "val_iter: 1000000\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "adam_kwargs:\n",
      "  ddis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  edis:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0005\n",
      "  enc_dec:\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.99\n",
      "    lr: 0.0002\n",
      "batch_size: 32\n",
      "checkpoint_root: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_2\n",
      "ddis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 128\n",
      "    - 128\n",
      "  type: residual9\n",
      "dec:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 256\n",
      "    - 256\n",
      "    - 128\n",
      "    - 64\n",
      "    - 32\n",
      "  type: residual9\n",
      "edis:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 1024\n",
      "    - 1024\n",
      "enc:\n",
      "  kwargs:\n",
      "    inner_dims:\n",
      "    - 32\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 256\n",
      "  type: residual9\n",
      "finetune_from: null\n",
      "image_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "image_dim: 1\n",
      "image_rec_loss:\n",
      "  loss_kwargs:\n",
      "    feature_weights:\n",
      "      r42: 1\n",
      "    img_weight: 0\n",
      "  loss_type: relative_perceptual_L1\n",
      "image_res: 64\n",
      "image_sample_iter: 5000\n",
      "initial_image_res: 64\n",
      "iters: 40000\n",
      "latent_adv_loss:\n",
      "  loss_kwargs:\n",
      "    gradient_penalty: 10\n",
      "    lambd: 1\n",
      "    norm_penalty: 0.001\n",
      "  loss_type: wasserstein\n",
      "latent_dim: 256\n",
      "latent_res: 1\n",
      "log_iter: 10\n",
      "log_root: ./data/logs_tmp/piad/nih/final/with_cv/class_subset/run_2\n",
      "n_dis: 2\n",
      "random_seed: 8189\n",
      "results_root: ./data/results/piad/nih/final/with_cv/class_subset/run_2\n",
      "test_batch_size: 32\n",
      "test_datasets:\n",
      "  anomaly:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/anomaly/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "  normal:\n",
      "    dataset_kwargs:\n",
      "      image_root: ./data/data/nih_300/\n",
      "      split: test\n",
      "      split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "    dataset_type: nih\n",
      "    transform_kwargs:\n",
      "      crop_size: 224\n",
      "      equalize_hist: true\n",
      "      resize: 64\n",
      "test_model_path: ./data/checkpoint_tmp/piad/nih/final/with_cv/class_subset/run_2/anomaly_detection.tar\n",
      "train_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "update_grad_norm_iter: 100\n",
      "val_dataset:\n",
      "  dataset_kwargs:\n",
      "    image_root: ./data/data/nih_300/\n",
      "    split: train\n",
      "    split_root: ./folds/train_test_split/nih/subset/normal/\n",
      "  dataset_type: nih\n",
      "  transform_kwargs:\n",
      "    crop_size: 224\n",
      "    equalize_hist: false\n",
      "    resize: 64\n",
      "val_iter: 1000000\n",
      "verbose: true\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/40000 [00:00<?, ?it/s]"
     ]
    }
   ]
  }
 ]
}
