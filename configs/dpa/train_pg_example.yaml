# EXAMPLE OF CONFIG FOR TRAINING WITH PROGRESSIVE GROWING

#=========================== CONFIG FOR TRAINING ===========================

verbose: True
random_seed: 4343
finetune_from:

# dir to store checkpoints
checkpoint_root: "./data/checkpoint/dpa/pg_example"
# dir to store logs
log_root: "./data/logs/dpa/pg_example"

#--------------------- Hyperparameters of training  ------------------------------

# maximum image resolution
max_image_res: 64
# initial image resolution (used in progressive growing training)
initial_image_res: 8
# number of image channels
image_dim: 1

# resolution and dimension of the latent tensor
latent_res: 1
latent_dim: 16

# Setting for progressive growing training
# trns_iter -- the number of iterations in the "transition phase" (gradual doubling of the resolution)
# stab_iter -- the number of iterations in the "stable phase", training on the fix resolution
# iters_per_res: use only if you want to specify different trns_iter of stab_iter for particular resolution.
# Example:
# iters_per_res:
#   64:
#     trns: 1000
#     stab: 2000
trns_iter: 20000
stab_iter: 20000
iters_per_res:
  64:
    stab: 3500

# val_iter -- perform validation every "val_iter" iteration
# (just to demonstrate losses in plots, and for early stopping in the last phase of training(max resolution, stab phase))
val_iter: 1000000
# early stopping used only the last phase of training (max resolution, stab phase)
# early stopping was used only during cross-validation
early_stopping_patience: 1000000
early_stopping_min_delta: 0.001

# log_iter -- log training losses every "log_iter" iteration
log_iter: 10

# sample example of images + reconstructed images every "image_sample_iter" iteration
image_sample_iter: 1000

#--------------------- Hyperparameters of optimizers ---------------------------

adam_kwargs:
  lr: 0.001

# specify batch_sizes for each resolution (from initial_image_res to max_image_res)
batch_sizes:
  8: 128
  16: 128
  32: 128
  64: 128

#--------------------- Hyperparameters of dataset  ------------------------------

train_dataset:
  # choose type [cifar10, svhn, camelyon16, nih]
  dataset_type: nih

  # specify kwargs, see more details in anomaly_detection/utils/datasets.py
  dataset_kwargs:
    image_root: "./data/data/nih_256"
    split_root: "./folds/train_test_split/nih/subset/normal/"
    split: train
    cache_data: true

  # specify transform kwargs, see more details in anomaly_detection/utils/transforms.py
  transform_kwargs:
    crop_size: 224
    equalize_hist: false
    resize: 64

# val_dataset mean something only during cross-validation only (for early stopping, for example).
# Just copy `train_dataset` params to `val_dataset` params (it will not affect anything).
val_dataset:
  # choose type [cifar10, svhn, camelyon16, nih]
  dataset_type: nih

  # specify kwargs, see more details in anomaly_detection/utils/datasets.py
  dataset_kwargs:
    image_root: "./data/data/nih_256"
    split_root: "./folds/train_test_split/nih/subset/normal/"
    split: train
    cache_data: true

  # specify transform kwargs, see more details in anomaly_detection/utils/transforms.py
  transform_kwargs:
    crop_size: 224
    equalize_hist: false
    resize: 64

#--------------------- Hyperparameters of models  ------------------------------

# hyperparameters of encoder
enc:
  # choose type [regular, residual9, residual18]
  type: residual18

  # specify kwargs, see more details in anomaly_detection/dpa/pg_encoders.py
  kwargs:
    # inner_dims -- numbers of channels in convolutions
    # for example if latent res = 1, image res = 64,
    # encoder consists from blocks of convolution for resolutions:  4, 8, 16, 32, 64
    # Therefore, you should specify 5 numbers, for example: [32, 64, 128, 256, 512]
    inner_dims: [16, 16, 16, 16, 16]

# hyperparameters of decoder
dec:
  # choose type [regular, residual9, residual18]
  type: residual18

  # specify kwargs, see more details in anomaly_detection/dpa/pg_decoders.py
  kwargs:
    # inner_dims -- numbers of channels in convolutions
    # for example if latent res = 1, image res = 64,
    # decoder consists from blocks of convolution for resolutions: 64, 32, 16, 8, 4
    # Therefore, you should specify 5 numbers, for example: [512, 128, 64, 32, 16]
    inner_dims: [16, 16, 16, 16, 16]

#--------------------- Hyperparameters of loss function ---------------------------


image_rec_loss:
  # choose type: [perceptual, relative_perceptual_L1, l1, l2, compose]
  loss_type: relative_perceptual_L1

  # specify kwargs, see more details in anomaly_detection/dpa/pg_rec_losses.py
  loss_kwargs:
    # weights_per_resolution -- a dict of feature layer weights (to compute perceptual loss) for each training resolution
    weights_per_resolution:
      8: # this is resolution
        # vgg19 convolutions are named as r11, r12, r21, r22, r31, r32, r33, r34, r41, r42, r43, r44, r51, r52, r53, r54
        # see more details in anomaly_detection/dpa/feature_extractor.py
        feature_weights:
          r12: 1
        img_weight: 0
      16:
        feature_weights:
          r22: 1
        img_weight: 0
      32:
        feature_weights:
          r32: 1
        img_weight: 0
      64:
        feature_weights:
          r42: 1
        img_weight: 0
    use_smooth_pg: true
